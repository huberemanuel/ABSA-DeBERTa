{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeBERTa Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPBhLqW8-9Qm",
        "outputId": "f35d8353-edc4-47e9-9188-2e373418ff9e"
      },
      "source": [
        "!rm -rf DeBERTa\n",
        "!git clone https://github.com/huberemanuel/DeBERTa.git\n",
        "!pip install -r DeBERTa/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeBERTa'...\n",
            "remote: Enumerating objects: 233, done.\u001b[K\n",
            "remote: Counting objects: 100% (233/233), done.\u001b[K\n",
            "remote: Compressing objects: 100% (165/165), done.\u001b[K\n",
            "remote: Total 397 (delta 142), reused 129 (delta 63), pack-reused 164\u001b[K\n",
            "Receiving objects: 100% (397/397), 434.81 KiB | 11.15 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 2)) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 3)) (1.19.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 4)) (3.6.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 5)) (2019.12.20)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 7)) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 8)) (4.41.1)\n",
            "Collecting ujson\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/84/e039c6ffc6603f2dfe966972d345d4f650a4ffd74b18c852ece645de12ac/ujson-4.0.1-cp36-cp36m-manylinux1_x86_64.whl (179kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 9.0MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r DeBERTa/requirements.txt (line 11)) (5.4.8)\n",
            "Collecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 21kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r DeBERTa/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (51.0.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r DeBERTa/requirements.txt (line 2)) (2.0.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r DeBERTa/requirements.txt (line 4)) (20.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r DeBERTa/requirements.txt (line 4)) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r DeBERTa/requirements.txt (line 4)) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->-r DeBERTa/requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->-r DeBERTa/requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r DeBERTa/requirements.txt (line 7)) (0.22.2.post1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r DeBERTa/requirements.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r DeBERTa/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r DeBERTa/requirements.txt (line 2)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r DeBERTa/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r DeBERTa/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r DeBERTa/requirements.txt (line 7)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r DeBERTa/requirements.txt (line 2)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r DeBERTa/requirements.txt (line 2)) (3.4.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=e024a09c4c013256ef7fbe413d867895bbae069f54bb9efb622809469c11e664\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ujson, seqeval, torch\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed seqeval-1.2.2 torch-1.3.0 ujson-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf_JgOiKEXJZ"
      },
      "source": [
        "# Setup experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quxPnjmIhcBS",
        "outputId": "fa8c6085-d9b7-4b0d-c0f2-5e8745e8f385"
      },
      "source": [
        "%%writefile DeBERTa/data/clean_data.py\n",
        "\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "output_dir = \"output\"\n",
        "train_split = 0.8\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "for csv_data in glob.glob(\"*.csv\"):\n",
        "    df = pd.read_csv(csv_data)\n",
        "\n",
        "    if \"train\" in csv_data:\n",
        "        df_train = df.sample(frac=train_split)\n",
        "        df_test = df.drop(df_train.index)\n",
        "\n",
        "        df_train.to_csv(f\"{output_dir}/{csv_data.split('.')[0]}.tsv\", sep='\\t', index=False)\n",
        "        test_filename = csv_data.replace(\"train\", \"dev\")\n",
        "        df_test.to_csv(f\"{output_dir}/{test_filename.split('.')[0]}.tsv\", sep='\\t', index=False)\n",
        "    else:\n",
        "        df.to_csv(f\"{output_dir}/{csv_data.split('.')[0]}.tsv\", sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting DeBERTa/data/clean_data.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzYTQmSqkj2V"
      },
      "source": [
        "!cd DeBERTa/data && python clean_data.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFG5MQEajAAj",
        "outputId": "34e29ede-28d1-4ddf-882f-91f7288dec45"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "for data_set in [\"train\", \"test\"]:\n",
        "    df_lap = pd.read_csv(f\"DeBERTa/data/laptop_{data_set}.csv\")\n",
        "    print(\"-\"*20)\n",
        "    print(\"laptop\")\n",
        "    print(df_lap.shape)\n",
        "    print(df_lap.sentiment.value_counts())\n",
        "    print(\"-\"*20)\n",
        "    df_rest = pd.read_csv(f\"DeBERTa/data/restaurants_{data_set}.csv\")\n",
        "    print(\"-\"*20)\n",
        "    print(\"rest\")\n",
        "    print(df_rest.shape)\n",
        "    print(df_rest.sentiment.value_counts())\n",
        "    df_combined = df_lap.append(df_rest)\n",
        "    print(\"Combined samples: \", df_combined.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------\n",
            "laptop\n",
            "(2328, 3)\n",
            " 1    994\n",
            "-1    870\n",
            " 0    464\n",
            "Name: sentiment, dtype: int64\n",
            "--------------------\n",
            "--------------------\n",
            "rest\n",
            "(3608, 3)\n",
            " 1    2164\n",
            "-1     807\n",
            " 0     637\n",
            "Name: sentiment, dtype: int64\n",
            "Combined samples:  (5936, 3)\n",
            "--------------------\n",
            "laptop\n",
            "(638, 3)\n",
            " 1    341\n",
            " 0    169\n",
            "-1    128\n",
            "Name: sentiment, dtype: int64\n",
            "--------------------\n",
            "--------------------\n",
            "rest\n",
            "(1120, 3)\n",
            " 1    728\n",
            "-1    196\n",
            " 0    196\n",
            "Name: sentiment, dtype: int64\n",
            "Combined samples:  (1758, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UwZSb0w_HIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc95de8-8618-413d-facb-b98ad1ddbbbb"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "for data_set in [\"train\", \"dev\", \"test\"]:\n",
        "    # df_lap = pd.read_csv(f\"DeBERTa/data/output/laptop_{data_set}_clean.tsv\", sep=\"\\t\")\n",
        "    df_lap = pd.read_csv(f\"DeBERTa/data/output/laptop_{data_set}.tsv\", sep=\"\\t\")\n",
        "    # df_rest = pd.read_csv(f\"DeBERTa/data/output/restaurants_{data_set}_clean.tsv\", sep=\"\\t\")\n",
        "    df_rest = pd.read_csv(f\"DeBERTa/data/output/restaurants_{data_set}.tsv\", sep=\"\\t\")\n",
        "    df_combined = df_lap.append(df_rest)\n",
        "    df_combined.to_csv(f\"DeBERTa/data/output/{data_set}.tsv\", index=False, sep=\"\\t\")\n",
        "    print(data_set)\n",
        "    print(df_combined.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train\n",
            "(4748, 3)\n",
            "dev\n",
            "(1188, 3)\n",
            "test\n",
            "(1758, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BMMf4GPWJnj",
        "outputId": "60ded5f0-6f51-4297-a321-75e151bb9384"
      },
      "source": [
        "!grep -rsn \"The bread is top notch\" DeBERTa/data/output/*.*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DeBERTa/data/output/restaurants_test.tsv:2:The bread is top notch as well .\tbread\t1\n",
            "DeBERTa/data/output/test.tsv:640:The bread is top notch as well .\tbread\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a8LQk2YR8JU"
      },
      "source": [
        "The execution will fail but the Semeval dataset will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIXQPoF-vc-E"
      },
      "source": [
        "!mkdir -p /tmp/DeBERTa/glue_tasks/QQP/\n",
        "!cp /content/DeBERTa/data/output/train.tsv /tmp/DeBERTa/glue_tasks/QQP/train.tsv\n",
        "!cp /content/DeBERTa/data/output/dev.tsv /tmp/DeBERTa/glue_tasks/QQP/dev.tsv\n",
        "!cp /content/DeBERTa/data/output/test.tsv /tmp/DeBERTa/glue_tasks/QQP/test.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPb7hENnwr5e",
        "outputId": "7b994090-5d76-4580-c141-aa0fea9af183"
      },
      "source": [
        "%%writefile DeBERTa/DeBERTa/training/dist_launcher.py\n",
        "\n",
        "# Copyright (c) Microsoft, Inc. 2020\n",
        "#\n",
        "# This source code is licensed under the MIT license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "# Author: penhe@microsoft.com\n",
        "# Date: 05/15/2019\n",
        "#\n",
        "\n",
        "import os\n",
        "import time\n",
        "import pdb\n",
        "import signal\n",
        "import torch\n",
        "from multiprocessing import Process,Pool\n",
        "from collections import defaultdict\n",
        "import sys\n",
        "import psutil\n",
        "from ..utils import set_logger, get_logger\n",
        "logger = get_logger()\n",
        "\n",
        "def kill_children(proc=None, recursive = True):\n",
        "  if proc is None:\n",
        "    proc = psutil.Process()\n",
        "  _children = proc.children(recursive=False)\n",
        "  for c in _children:\n",
        "    try:\n",
        "      if recursive:\n",
        "        kill_children(c, recursive=recursive)\n",
        "      os.kill(c.pid, signal.SIGKILL)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  for c in _children:\n",
        "    try:\n",
        "      c.wait(1)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "def gc(i):\n",
        "  return torch.cuda.device_count()\n",
        "\n",
        "def get_ngpu():\n",
        "  return 0\n",
        "  with Pool(1) as p:\n",
        "    return p.map(gc, range(1))[0]\n",
        "\n",
        "def _setup_distributed_group(args):\n",
        "  \"\"\"Initialize torch.distributed.\"\"\"\n",
        "\n",
        "  torch.backends.cudnn.enabled = False\n",
        "  args.world_size = 1\n",
        "  if args.world_size == 1:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  else:\n",
        "    set_logger(args.task_name, os.path.join(args.output_dir, f'training_{args.task_name}_{args.rank}.log'), rank=args.rank, verbose=1 if args.local_rank==0 else 0)\n",
        "    device_id = args.rank % args.n_gpu if args.n_gpu > 0 else 0\n",
        "    if args.local_rank >= 0:\n",
        "      device_id = args.local_rank\n",
        "    device = torch.device(\"cuda\", device_id)\n",
        "    init_method = 'tcp://'\n",
        "    init_method += args.master_ip + ':' + args.master_port\n",
        "    distributed_backend = getattr(args, 'distributed_backend', 'nccl')\n",
        "    torch.distributed.init_process_group(\n",
        "      backend=distributed_backend,\n",
        "      world_size=args.world_size, rank=args.rank,\n",
        "      init_method=init_method)\n",
        "    torch.cuda.set_device(device)\n",
        "  n_gpu = torch.cuda.device_count()\n",
        "  logger.info(\"device=%s, n_gpu=%d, distributed training=%r, world_size=%d\", device, n_gpu, bool(args.world_size != 1), args.world_size)\n",
        "  return device\n",
        "\n",
        "def _get_world_size(args):\n",
        "    world_size = int(os.getenv(\"WORLD_SIZE\", '1'))\n",
        "    if not hasattr(args, 'n_gpu') or args.n_gpu is None:\n",
        "      n_gpu = get_ngpu()\n",
        "    return n_gpu * world_size\n",
        "\n",
        "def initialize_distributed(args, join=True):\n",
        "    args.world_size = int(os.getenv(\"WORLD_SIZE\", '1'))\n",
        "    args.rank = int(os.getenv('RANK', '0'))\n",
        "    args.master_ip = os.getenv('MASTER_ADDR', 'localhost')\n",
        "    args.master_port = os.getenv('MASTER_PORT', '17006')\n",
        "  \n",
        "    if args.world_size == 1:\n",
        "      args.rank = 0\n",
        "      args.master_ip = 'localhost'\n",
        "\n",
        "    if not hasattr(args, 'n_gpu') or args.n_gpu is None:\n",
        "      args.n_gpu = get_ngpu()\n",
        "\n",
        "    args.node_rank = args.rank\n",
        "    args.world_size = args.n_gpu * args.world_size\n",
        "    seed = args.seed\n",
        "    is_child = False\n",
        "    if args.world_size>1:\n",
        "      children = []\n",
        "      for r in range(args.n_gpu):\n",
        "        args.rank = r + args.n_gpu*args.node_rank\n",
        "        args.local_rank = r\n",
        "        args.seed = seed + args.rank\n",
        "        child = os.fork()\n",
        "        if child>0:\n",
        "          children.append(child)\n",
        "        else:\n",
        "          signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
        "          is_child = True\n",
        "          break\n",
        "    else:\n",
        "      is_child = True\n",
        "\n",
        "    if is_child:\n",
        "      return _setup_distributed_group(args)\n",
        "    else:\n",
        "      if join:\n",
        "        try:\n",
        "          for c in children:\n",
        "            cid, ccode = os.waitpid(0,0)\n",
        "            logger.debug(f'Worker {c} done with code {ccode}')\n",
        "            if ccode != 0:\n",
        "              logger.error(f'Worker {c} : {cid} failed with code {ccode}')\n",
        "              kill_children()\n",
        "              raise ValueError(f'Job failed. {cid}:{ccode}')\n",
        "        except (KeyboardInterrupt, SystemExit):\n",
        "          logger.warning('Keybord interrupt by user. Terminate all processes')\n",
        "          kill_children(None)\n",
        "      return children\n",
        "\n",
        "def test_dist_launch():\n",
        "  def test_functions(args):\n",
        "    global logger\n",
        "    set_logger(args.task_name, os.path.join(args.output_dir, f'training_{args.task_name}_{args.node_rank}.log'), rank=args.rank)\n",
        "    logger.info(args)\n",
        "\n",
        "  class Args:\n",
        "    def __init__(self):\n",
        "      pass\n",
        "    def __repr__(self):\n",
        "      return str(self.__dict__)\n",
        "\n",
        "  args = Args()\n",
        "  args.task_name = 'test'\n",
        "  args.seed = 0\n",
        "  args.n_gpu = None\n",
        "  args.no_cuda=False\n",
        "  args.output_dir = '/tmp'\n",
        "  distributed_launch(args, test_functions, (args,))\n",
        "\n",
        "def test_init_dist():\n",
        "  class Args:\n",
        "    def __init__(self):\n",
        "      pass\n",
        "    def __repr__(self):\n",
        "      return str(self.__dict__)\n",
        "\n",
        "  args = Args()\n",
        "  args.task_name = 'test'\n",
        "  args.seed = 0\n",
        "  args.n_gpu = None\n",
        "  args.no_cuda=False\n",
        "  args.output_dir = '/tmp'\n",
        "  device = initialize_distributed(args)\n",
        "  if isinstance(device, torch.device):\n",
        "    return 0\n",
        "  else:\n",
        "    return 1\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting DeBERTa/DeBERTa/training/dist_launcher.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p0A46acR6nA",
        "outputId": "d9fc4a10-c05e-4eeb-b646-9d7ea9b8c91f"
      },
      "source": [
        "!chmod +x /content/DeBERTa/experiments/glue/qqp_base.sh\n",
        "!/content/DeBERTa/experiments/glue/qqp_base.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  8459  100  8459    0     0  18881      0 --:--:-- --:--:-- --:--:-- 18881\n",
            "Downloading and extracting QQP...\n",
            "Traceback (most recent call last):\n",
            "  File \"<stdin>\", line 172, in <module>\n",
            "  File \"<stdin>\", line 168, in main\n",
            "  File \"<stdin>\", line 57, in download_and_extract\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 248, in urlretrieve\n",
            "    with contextlib.closing(urlopen(url, data)) as fp:\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 223, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 532, in open\n",
            "    response = meth(req, response)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
            "    'http', request, response, code, msg, hdrs)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 570, in error\n",
            "    return self._call_chain(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
            "    result = func(*args)\n",
            "  File \"/usr/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 403: Forbidden\n",
            "01/02/2021 17:41:01|INFO|QQP|00| Namespace(accumulative_update=1, adam_beta1=0.9, adam_beta2=0.999, cls_drop_out=0.15, data_dir='/tmp/DeBERTa//glue_tasks/QQP', debug=False, do_eval=True, do_predict=True, do_train=True, dump_interval=5000, epsilon=1e-06, eval_batch_size=128, fp16=True, init_model='base', learning_rate=1e-05, local_rank=-1, lookahead_alpha=0.5, lookahead_k=-1, loss_scale=16384.0, lr_schedule='warmup_linear', lr_schedule_ends=0, max_grad_norm=1, max_seq_length=256, model_config='/tmp/ttonly/Base/QQP/model_config.json', num_train_epochs=32.0, opt_type='adam', output_dir='/tmp/ttonly/Base/QQP', pre_trained=None, predict_batch_size=128, scale_steps=250, seed=1234, tag='deberta_Base', task_name='QQP', train_batch_size=16, warmup_proportion=500.0, weight_decay=0.01, with_radam=False, workers=1)\n",
            "Downloading bpe_encoder.zip: 100%|█| 1590981/1590981 [00:00<00:00, 4061251.13it/\n",
            "01/02/2021 17:41:03|ERROR|QQP|00| Uncatched exception happened during execution.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeBERTa/DeBERTa/apps/train.py\", line 448, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DeBERTa/DeBERTa/apps/train.py\", line 233, in main\n",
            "    eval_data = processor.eval_data(max_seq_len=args.max_seq_length)\n",
            "  File \"/content/DeBERTa/DeBERTa/apps/glue_tasks.py\", line 558, in eval_data\n",
            "    self._data('dev', 'dev.tsv', 'dev')\n",
            "  File \"/content/DeBERTa/DeBERTa/apps/glue_tasks.py\", line 583, in _data\n",
            "    assert os.path.exists(input_src), f\"{input_src} doesn't exists\"\n",
            "AssertionError: /tmp/DeBERTa//glue_tasks/QQP/dev.tsv doesn't exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0IR_2wARyL6"
      },
      "source": [
        "Running the experiment for a specific dataset (laptop, restaurants)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E2g9FY2EWjW"
      },
      "source": [
        "dataset = \"laptop\"\n",
        "!cp /content/DeBERTa/data/output/{dataset}_train_clean.tsv /tmp/DeBERTa/glue_tasks/QQP/train.tsv\n",
        "!cp /content/DeBERTa/data/output/{dataset}_dev_clean.tsv /tmp/DeBERTa/glue_tasks/QQP/dev.tsv\n",
        "# !cp /content/DeBERTa/data/output/{dataset}_test_clean.tsv /tmp/DeBERTa/glue_tasks/QQP/test.tsv\n",
        "!cp /content/DeBERTa/data/output/test.tsv /tmp/DeBERTa/glue_tasks/QQP/test.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-KSN2enR18I"
      },
      "source": [
        "Para rodar o experimento com os datasets combinados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN2_NARLAJ8_"
      },
      "source": [
        "!cp /content/DeBERTa/data/output/train.tsv /tmp/DeBERTa/glue_tasks/QQP/train.tsv\n",
        "!cp /content/DeBERTa/data/output/dev.tsv /tmp/DeBERTa/glue_tasks/QQP/dev.tsv\n",
        "!cp /content/DeBERTa/data/output/test.tsv /tmp/DeBERTa/glue_tasks/QQP/test.tsv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHKTlgvN0tFz",
        "outputId": "a56df769-926a-4c27-a226-b20380fb1b8c"
      },
      "source": [
        "# !cd DeBERTa/data && python clean_data.py\n",
        "!head DeBERTa/data/output/train.tsv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review\taspect\tsentiment\n",
            "-4 RAM slots , 2 HDD Bays * , 16GB RAM support - No Wireless Issues , at least for me .\tWireless\t1\n",
            "Quality Display I was surprised with the performance and quality of this HP Laptop .\tQuality Display\t1\n",
            "-LRB- The SATA controller is the motherboard chip that lets the CPU talk to the hard drive . -RRB-\tCPU\t0\n",
            "Fan vents to the side , so no cooling pad needed , great feature !\tFan\t1\n",
            "Everything is so easy to use , Mac software is just so much simpler than Microsoft software .\tuse\t1\n",
            "Also , HDD secures inside using rails , and there is only one set on the main hard drive .\tHDD\t1\n",
            "The display is incredibly bright , much brighter than my PowerBook and very crisp .\tdisplay\t1\n",
            "Cords coming out the right for power plus cords coming out front for headphones/mic plus network connection on left make for a very messy setup with cords going every direction .\tCords\t-1\n",
            "The board has a bad connector with the power supply and shortly after warrenty expires the power supply will start having issues .\twarrenty\t-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmHOsdOeSDln"
      },
      "source": [
        "Experiment execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOiQxHYiCJkt",
        "outputId": "597797f8-fb6b-4f55-c250-7ca03d32e401"
      },
      "source": [
        "%%writefile /content/DeBERTa/experiments/glue/qqp_base.sh\n",
        "#!/bin/bash\n",
        "SCRIPT=$(readlink -f \"$0\")\n",
        "SCRIPT_DIR=$(dirname \"$SCRIPT\")\n",
        "cd $SCRIPT_DIR\n",
        "\n",
        "cache_dir=/tmp/DeBERTa/\n",
        "\n",
        "function setup_glue_data(){\n",
        "\ttask=$1\n",
        "\tmkdir -p $cache_dir\n",
        "\tif [[ ! -e $cache_dir/glue_tasks/${task}/train.tsv ]]; then\n",
        "\t\tcurl -J -L https://raw.githubusercontent.com/nyu-mll/jiant/v1.3.2/scripts/download_glue_data.py | python3 - --data_dir $cache_dir/glue_tasks --tasks $task\n",
        "\tfi\n",
        "}\n",
        "\n",
        "init=base \n",
        "\n",
        "tag=Base\n",
        "Task=QQP\n",
        "setup_glue_data $Task\n",
        "../utils/train.sh -i $init -p --config config.json -t $Task --data $cache_dir/glue_tasks/$Task --tag $tag -o /tmp/ttonly/$tag/$task -- --num_train_epochs 10 --accumulative_update 1 --warmup 500 --learning_rate 1e-5 --train_batch_size 16 --max_seq_length 256 --dump 5000 --cls_drop 0.15 --fp16 True\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/DeBERTa/experiments/glue/qqp_base.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1JyGYfzWmvq"
      },
      "source": [
        "!rm -rf /tmp/ttonly/Base/QQP/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2zRl40x8gcn",
        "outputId": "a42ad192-7f55-4a01-ef88-58b0726bfedc"
      },
      "source": [
        "!chmod +x /content/DeBERTa/experiments/glue/qqp_base.sh\n",
        "!/content/DeBERTa/experiments/glue/qqp_base.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/15/2020 01:19:28|INFO|QQP|00| Namespace(accumulative_update=1, adam_beta1=0.9, adam_beta2=0.999, cls_drop_out=0.15, data_dir='/tmp/DeBERTa//glue_tasks/QQP', debug=False, do_eval=True, do_predict=True, do_train=True, dump_interval=5000, epsilon=1e-06, eval_batch_size=128, fp16=True, init_model='base', learning_rate=1e-05, local_rank=-1, lookahead_alpha=0.5, lookahead_k=-1, loss_scale=16384.0, lr_schedule='warmup_linear', lr_schedule_ends=0, max_grad_norm=1, max_seq_length=256, model_config='/tmp/ttonly/Base/QQP/model_config.json', num_train_epochs=10.0, opt_type='adam', output_dir='/tmp/ttonly/Base/QQP', pre_trained=None, predict_batch_size=128, scale_steps=250, seed=1234, tag='deberta_Base', task_name='QQP', train_batch_size=16, warmup_proportion=500.0, weight_decay=0.01, with_radam=False, workers=1)\n",
            "12/15/2020 01:19:28|INFO|QQP|00| Total corpus examples: 1188\n",
            "12/15/2020 01:19:28|INFO|QQP|00|   Evaluation batch size = 128\n",
            "12/15/2020 01:19:29|INFO|QQP|00| Total corpus examples: 1758\n",
            "12/15/2020 01:19:29|INFO|QQP|00|   Prediction batch size = 128\n",
            "12/15/2020 01:19:30|INFO|QQP|00| Total corpus examples: 4748\n",
            "Downloading base.zip: 100%|█| 520086661/520086661 [00:07<00:00, 68932678.46it/s]\n",
            "12/15/2020 01:19:42|INFO|QQP|00| Loaded pre-trained model file /root/.~DeBERTa/assets/latest/base/pytorch.model.bin\n",
            "12/15/2020 01:19:44|INFO|QQP|00| Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"padding_idx\": 0,\n",
            "  \"pooling\": {\n",
            "    \"dropout\": 0,\n",
            "    \"hidden_act\": \"gelu\"\n",
            "  },\n",
            "  \"pos_att_type\": \"c2p|p2c\",\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "12/15/2020 01:19:44|INFO|QQP|00| device=cuda, n_gpu=1, distributed training=False, world_size=1\n",
            "Evaluating: deberta_Base: 100%|█████████████████| 10/10 [00:11<00:00,  1.10s/it]\n",
            "12/15/2020 01:20:00|INFO|QQP|00| ***** Eval results-dev-deberta_Base *****\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   accuracy = 0.27525252525252525\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   eval_loss = 1.103509294986725\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   eval_metric = 0.22900184382583263\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   f1 = 0.18275116239914002\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   Training batch size = 16\n",
            "12/15/2020 01:20:00|INFO|QQP|00|   Num steps = 2967\n",
            "12/15/2020 01:20:48|INFO|QQP|00| [3.4%][-0.38h] Steps=100, loss=1.065401527285576, examples=1600, loss_scale=16384.0, 48.0s\n",
            "12/15/2020 01:21:39|INFO|QQP|00| [6.7%][-0.39h] Steps=200, loss=0.9192772130668163, examples=3200, loss_scale=8192.0, 50.4s\n",
            "12/15/2020 01:22:30|INFO|QQP|00| [10.0%][-0.39h] Steps=297, loss=0.8223873820369091, examples=4748, loss_scale=2048.0, 50.8s\n",
            "Evaluating: 000297-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
            "12/15/2020 01:22:44|INFO|QQP|00| ***** Eval results-dev-000297-2967 *****\n",
            "12/15/2020 01:22:44|INFO|QQP|00|   accuracy = 0.7920875420875421\n",
            "12/15/2020 01:22:44|INFO|QQP|00|   eval_loss = 0.5554894655942917\n",
            "12/15/2020 01:22:44|INFO|QQP|00|   eval_metric = 0.7479084638476299\n",
            "12/15/2020 01:22:44|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:22:44|INFO|QQP|00|   f1 = 0.7037293856077178\n",
            "12/15/2020 01:22:44|INFO|QQP|00| Best metric: 0.7479084638476299@297\n",
            "12/15/2020 01:22:46|INFO|QQP|00| [10.1%][-3.98h] Steps=300, loss=0.820676195025444, examples=4796, loss_scale=2048.0, 16.1s\n",
            "12/15/2020 01:23:37|INFO|QQP|00| [13.5%][-0.37h] Steps=400, loss=0.7469391699135304, examples=6396, loss_scale=2048.0, 51.4s\n",
            "12/15/2020 01:24:28|INFO|QQP|00| [16.9%][-0.35h] Steps=500, loss=0.705260989099741, examples=7996, loss_scale=4096.0, 51.2s\n",
            "12/15/2020 01:25:16|INFO|QQP|00| [20.0%][-0.34h] Steps=594, loss=0.6764106989057377, examples=9496, loss_scale=4096.0, 48.0s\n",
            "Evaluating: 000594-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
            "12/15/2020 01:25:31|INFO|QQP|00| ***** Eval results-dev-000594-2967 *****\n",
            "12/15/2020 01:25:31|INFO|QQP|00|   accuracy = 0.8198653198653199\n",
            "12/15/2020 01:25:31|INFO|QQP|00|   eval_loss = 0.4673301488161087\n",
            "12/15/2020 01:25:31|INFO|QQP|00|   eval_metric = 0.7876381373574428\n",
            "12/15/2020 01:25:31|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:25:31|INFO|QQP|00|   f1 = 0.7554109548495659\n",
            "12/15/2020 01:25:31|INFO|QQP|00| Best metric: 0.7876381373574428@594\n",
            "12/15/2020 01:25:34|INFO|QQP|00| [20.2%][-1.93h] Steps=600, loss=0.6721612773090601, examples=9592, loss_scale=4096.0, 17.6s\n",
            "12/15/2020 01:26:26|INFO|QQP|00| [23.6%][-0.33h] Steps=700, loss=0.6255727336236409, examples=11192, loss_scale=2048.0, 51.8s\n",
            "12/15/2020 01:27:17|INFO|QQP|00| [27.0%][-0.31h] Steps=800, loss=0.5939249171502888, examples=12792, loss_scale=2048.0, 51.3s\n",
            "12/15/2020 01:28:04|INFO|QQP|00| [30.0%][-0.29h] Steps=891, loss=0.5663849740350821, examples=14244, loss_scale=2048.0, 46.5s\n",
            "Evaluating: 000891-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:28:18|INFO|QQP|00| ***** Eval results-dev-000891-2967 *****\n",
            "12/15/2020 01:28:18|INFO|QQP|00|   accuracy = 0.8417508417508418\n",
            "12/15/2020 01:28:18|INFO|QQP|00|   eval_loss = 0.4320283353328705\n",
            "12/15/2020 01:28:18|INFO|QQP|00|   eval_metric = 0.8210801209401539\n",
            "12/15/2020 01:28:18|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:28:18|INFO|QQP|00|   f1 = 0.8004094001294662\n",
            "12/15/2020 01:28:18|INFO|QQP|00| Best metric: 0.8210801209401539@891\n",
            "12/15/2020 01:28:23|INFO|QQP|00| [30.3%][-1.22h] Steps=900, loss=0.5626893741968605, examples=14388, loss_scale=2048.0, 19.2s\n",
            "12/15/2020 01:29:14|INFO|QQP|00| [33.7%][-0.28h] Steps=1000, loss=0.5287649126201868, examples=15988, loss_scale=4096.0, 51.2s\n",
            "12/15/2020 01:30:05|INFO|QQP|00| [37.1%][-0.27h] Steps=1100, loss=0.5045012168789452, examples=17588, loss_scale=4096.0, 51.3s\n",
            "12/15/2020 01:30:50|INFO|QQP|00| [40.0%][-0.25h] Steps=1188, loss=0.4854248119424088, examples=18992, loss_scale=4096.0, 45.0s\n",
            "Evaluating: 001188-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:31:05|INFO|QQP|00| ***** Eval results-dev-001188-2967 *****\n",
            "12/15/2020 01:31:05|INFO|QQP|00|   accuracy = 0.8383838383838383\n",
            "12/15/2020 01:31:05|INFO|QQP|00|   eval_loss = 0.5279724508523941\n",
            "12/15/2020 01:31:05|INFO|QQP|00|   eval_metric = 0.8188202466465848\n",
            "12/15/2020 01:31:05|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:31:05|INFO|QQP|00|   f1 = 0.7992566549093313\n",
            "12/15/2020 01:31:05|INFO|QQP|00| Best metric: 0.8210801209401539@891\n",
            "12/15/2020 01:31:11|INFO|QQP|00| [40.4%][-0.85h] Steps=1200, loss=0.4826498941021661, examples=19184, loss_scale=4096.0, 20.8s\n",
            "12/15/2020 01:32:03|INFO|QQP|00| [43.8%][-0.24h] Steps=1300, loss=0.45904519587755205, examples=20784, loss_scale=8192.0, 51.4s\n",
            "12/15/2020 01:32:54|INFO|QQP|00| [47.2%][-0.22h] Steps=1400, loss=0.43682952406150954, examples=22384, loss_scale=8192.0, 51.3s\n",
            "12/15/2020 01:33:37|INFO|QQP|00| [50.1%][-0.21h] Steps=1485, loss=0.4218911829269695, examples=23740, loss_scale=16384.0, 43.4s\n",
            "Evaluating: 001485-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:33:52|INFO|QQP|00| ***** Eval results-dev-001485-2967 *****\n",
            "12/15/2020 01:33:52|INFO|QQP|00|   accuracy = 0.8602693602693603\n",
            "12/15/2020 01:33:52|INFO|QQP|00|   eval_loss = 0.5242859452962876\n",
            "12/15/2020 01:33:52|INFO|QQP|00|   eval_metric = 0.8429578099568666\n",
            "12/15/2020 01:33:52|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:33:52|INFO|QQP|00|   f1 = 0.8256462596443729\n",
            "12/15/2020 01:33:52|INFO|QQP|00| Best metric: 0.8429578099568666@1485\n",
            "12/15/2020 01:34:00|INFO|QQP|00| [50.6%][-0.60h] Steps=1500, loss=0.41819993331531685, examples=23980, loss_scale=16384.0, 22.3s\n",
            "12/15/2020 01:34:51|INFO|QQP|00| [53.9%][-0.19h] Steps=1600, loss=0.39904717293567954, examples=25580, loss_scale=16384.0, 51.2s\n",
            "12/15/2020 01:35:42|INFO|QQP|00| [57.3%][-0.18h] Steps=1700, loss=0.3825058815694031, examples=27180, loss_scale=8192.0, 51.5s\n",
            "12/15/2020 01:36:24|INFO|QQP|00| [60.1%][-0.17h] Steps=1782, loss=0.3723255309112178, examples=28488, loss_scale=4096.0, 42.1s\n",
            "Evaluating: 001782-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.25s/it]\n",
            "12/15/2020 01:36:39|INFO|QQP|00| ***** Eval results-dev-001782-2967 *****\n",
            "12/15/2020 01:36:39|INFO|QQP|00|   accuracy = 0.8678451178451179\n",
            "12/15/2020 01:36:39|INFO|QQP|00|   eval_loss = 0.6036805927753448\n",
            "12/15/2020 01:36:39|INFO|QQP|00|   eval_metric = 0.8488112826586389\n",
            "12/15/2020 01:36:39|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:36:39|INFO|QQP|00|   f1 = 0.8297774474721601\n",
            "12/15/2020 01:36:39|INFO|QQP|00| Best metric: 0.8488112826586389@1782\n",
            "12/15/2020 01:36:48|INFO|QQP|00| [60.7%][-0.43h] Steps=1800, loss=0.3691172658010489, examples=28776, loss_scale=4096.0, 23.7s\n",
            "12/15/2020 01:37:39|INFO|QQP|00| [64.0%][-0.15h] Steps=1900, loss=0.35418579432721203, examples=30376, loss_scale=4096.0, 51.0s\n",
            "12/15/2020 01:38:30|INFO|QQP|00| [67.4%][-0.14h] Steps=2000, loss=0.3422469914946705, examples=31976, loss_scale=4096.0, 51.3s\n",
            "12/15/2020 01:39:10|INFO|QQP|00| [70.1%][-0.12h] Steps=2079, loss=0.3330563193257896, examples=33236, loss_scale=4096.0, 39.9s\n",
            "Evaluating: 002079-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:39:25|INFO|QQP|00| ***** Eval results-dev-002079-2967 *****\n",
            "12/15/2020 01:39:25|INFO|QQP|00|   accuracy = 0.8754208754208754\n",
            "12/15/2020 01:39:25|INFO|QQP|00|   eval_loss = 0.6542677551507949\n",
            "12/15/2020 01:39:25|INFO|QQP|00|   eval_metric = 0.8575463719047378\n",
            "12/15/2020 01:39:25|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:39:25|INFO|QQP|00|   f1 = 0.8396718683886001\n",
            "12/15/2020 01:39:25|INFO|QQP|00| Best metric: 0.8575463719047378@2079\n",
            "12/15/2020 01:39:36|INFO|QQP|00| [70.8%][-0.29h] Steps=2100, loss=0.33117866177466654, examples=33572, loss_scale=4096.0, 25.4s\n",
            "12/15/2020 01:40:27|INFO|QQP|00| [74.1%][-0.11h] Steps=2200, loss=0.3200184972397983, examples=35172, loss_scale=4096.0, 50.9s\n",
            "12/15/2020 01:41:18|INFO|QQP|00| [77.5%][-0.09h] Steps=2300, loss=0.30915186947292606, examples=36772, loss_scale=4096.0, 51.1s\n",
            "12/15/2020 01:41:56|INFO|QQP|00| [80.1%][-0.08h] Steps=2376, loss=0.30180814671439904, examples=37984, loss_scale=4096.0, 38.5s\n",
            "Evaluating: 002376-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:42:11|INFO|QQP|00| ***** Eval results-dev-002376-2967 *****\n",
            "12/15/2020 01:42:11|INFO|QQP|00|   accuracy = 0.8585858585858586\n",
            "12/15/2020 01:42:11|INFO|QQP|00|   eval_loss = 0.7514532208442688\n",
            "12/15/2020 01:42:11|INFO|QQP|00|   eval_metric = 0.843109010117187\n",
            "12/15/2020 01:42:11|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:42:11|INFO|QQP|00|   f1 = 0.8276321616485154\n",
            "12/15/2020 01:42:11|INFO|QQP|00| Best metric: 0.8575463719047378@2079\n",
            "12/15/2020 01:42:23|INFO|QQP|00| [80.9%][-0.18h] Steps=2400, loss=0.29969984215839457, examples=38368, loss_scale=4096.0, 26.8s\n",
            "12/15/2020 01:43:14|INFO|QQP|00| [84.3%][-0.07h] Steps=2500, loss=0.2899500866487622, examples=39968, loss_scale=4096.0, 50.9s\n",
            "12/15/2020 01:44:05|INFO|QQP|00| [87.6%][-0.05h] Steps=2600, loss=0.28084170735656067, examples=41568, loss_scale=4096.0, 51.1s\n",
            "12/15/2020 01:44:42|INFO|QQP|00| [90.1%][-0.04h] Steps=2673, loss=0.2755825640044875, examples=42732, loss_scale=4096.0, 37.0s\n",
            "Evaluating: 002673-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:44:56|INFO|QQP|00| ***** Eval results-dev-002673-2967 *****\n",
            "12/15/2020 01:44:56|INFO|QQP|00|   accuracy = 0.8653198653198653\n",
            "12/15/2020 01:44:56|INFO|QQP|00|   eval_loss = 0.7406140089035034\n",
            "12/15/2020 01:44:56|INFO|QQP|00|   eval_metric = 0.8487811112284513\n",
            "12/15/2020 01:44:56|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:44:56|INFO|QQP|00|   f1 = 0.8322423571370375\n",
            "12/15/2020 01:44:56|INFO|QQP|00| Best metric: 0.8575463719047378@2079\n",
            "12/15/2020 01:45:10|INFO|QQP|00| [91.0%][-0.08h] Steps=2700, loss=0.2732258039726703, examples=43164, loss_scale=4096.0, 28.4s\n",
            "12/15/2020 01:46:01|INFO|QQP|00| [94.4%][-0.02h] Steps=2800, loss=0.2658250640505659, examples=44764, loss_scale=4096.0, 50.8s\n",
            "12/15/2020 01:46:52|INFO|QQP|00| [97.7%][-0.01h] Steps=2900, loss=0.2590176592291943, examples=46364, loss_scale=4096.0, 51.1s\n",
            "12/15/2020 01:47:26|INFO|QQP|00| [100.0%][-0.00h] Steps=2967, loss=0.2544175736219404, examples=47436, loss_scale=4096.0, 34.1s\n",
            "Evaluating: 002967-2967: 100%|██████████████████| 10/10 [00:12<00:00,  1.26s/it]\n",
            "12/15/2020 01:47:41|INFO|QQP|00| ***** Eval results-dev-002967-2967 *****\n",
            "12/15/2020 01:47:41|INFO|QQP|00|   accuracy = 0.8661616161616161\n",
            "12/15/2020 01:47:41|INFO|QQP|00|   eval_loss = 0.7365419954061508\n",
            "12/15/2020 01:47:41|INFO|QQP|00|   eval_metric = 0.8490443424653951\n",
            "12/15/2020 01:47:41|INFO|QQP|00|   eval_samples = 1188\n",
            "12/15/2020 01:47:41|INFO|QQP|00|   f1 = 0.8319270687691741\n",
            "12/15/2020 01:47:41|INFO|QQP|00| Best metric: 0.8575463719047378@2079\n",
            "Evaluating: deberta_Base: 100%|█████████████████| 14/14 [00:18<00:00,  1.32s/it]\n",
            "12/15/2020 01:47:59|INFO|QQP|00| ***** Dump prediction results-test-deberta_Base *****\n",
            "12/15/2020 01:47:59|INFO|QQP|00| Location: /tmp/ttonly/Base/QQP/test_logits_test_deberta_Base.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kogmTNYgU2e8"
      },
      "source": [
        "Results export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1-1p0XTQFTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bebc6c0-f253-4abb-eb54-a5ce15fa4697"
      },
      "source": [
        "# !rm -rf /tmp/ttonly/Base/QQP/*.*\n",
        "!ls -loh /tmp/ttonly/Base/QQP/pytorch*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root 532M Dec  3 17:50 /tmp/ttonly/Base/QQP/pytorch.model-000297.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 17:52 /tmp/ttonly/Base/QQP/pytorch.model-000594.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 17:55 /tmp/ttonly/Base/QQP/pytorch.model-000891.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 17:58 /tmp/ttonly/Base/QQP/pytorch.model-001188.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:01 /tmp/ttonly/Base/QQP/pytorch.model-001485.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:03 /tmp/ttonly/Base/QQP/pytorch.model-001782.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:06 /tmp/ttonly/Base/QQP/pytorch.model-002079.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:09 /tmp/ttonly/Base/QQP/pytorch.model-002376.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:12 /tmp/ttonly/Base/QQP/pytorch.model-002673.bin\n",
            "-rw-r--r-- 1 root 532M Dec  3 18:14 /tmp/ttonly/Base/QQP/pytorch.model-002967.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnyUunvhe1kU"
      },
      "source": [
        "# !zip -r -9 /content/laptop_b32_v256.zip /tmp/ttonly/Base/QQP\n",
        "\n",
        "!rm -rf  /content/output/\n",
        "!mkdir /content/output/\n",
        "!cp /tmp/ttonly/Base/QQP/*.txt /content/output/\n",
        "!cp /tmp/ttonly/Base/QQP/*.json /content/output/\n",
        "!cp /tmp/ttonly/Base/QQP/*.tsv /content/output/\n",
        "!cp /tmp/ttonly/Base/QQP/*.log /content/output/\n",
        "!cp /tmp/ttonly/Base/QQP/pytorch.model-002967.bin /content/output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ3NdjupFFu6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12106010-7f0f-4129-f639-822f35fc9eb8"
      },
      "source": [
        "!zip -r -9 /content/all_b64_v256.zip /content/output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/eval_results_dev_deberta_Base.txt (deflated 28%)\n",
            "  adding: content/output/eval_results_dev_001485-2967.txt (deflated 24%)\n",
            "  adding: content/output/eval_results_dev_001782-2967.txt (deflated 25%)\n",
            "  adding: content/output/submit-dev-001188-2967.tsv (deflated 64%)\n",
            "  adding: content/output/eval_results_dev_002079-2967.txt (deflated 26%)\n",
            "  adding: content/output/eval_results_dev_002673-2967.txt (deflated 28%)\n",
            "  adding: content/output/submit-dev-000891-2967.tsv (deflated 64%)\n",
            "  adding: content/output/submit-dev-deberta_Base.tsv (deflated 68%)\n",
            "  adding: content/output/pytorch.model-002967.bin (deflated 13%)\n",
            "  adding: content/output/submit-dev-000297-2967.tsv (deflated 64%)\n",
            "  adding: content/output/submit-dev-002673-2967.tsv (deflated 64%)\n",
            "  adding: content/output/eval_results_dev_002967-2967.txt (deflated 25%)\n",
            "  adding: content/output/eval_results_dev_002376-2967.txt (deflated 27%)\n",
            "  adding: content/output/submit-dev-001782-2967.tsv (deflated 64%)\n",
            "  adding: content/output/training_QQP.log (deflated 74%)\n",
            "  adding: content/output/eval_results_dev_001188-2967.txt (deflated 27%)\n",
            "  adding: content/output/submit-dev-002967-2967.tsv (deflated 64%)\n",
            "  adding: content/output/eval_results_dev_000891-2967.txt (deflated 27%)\n",
            "  adding: content/output/submit-dev-000594-2967.tsv (deflated 64%)\n",
            "  adding: content/output/submit-dev-001485-2967.tsv (deflated 64%)\n",
            "  adding: content/output/submit-test-deberta_Base.tsv (deflated 64%)\n",
            "  adding: content/output/submit-dev-002079-2967.tsv (deflated 64%)\n",
            "  adding: content/output/model_config.json (deflated 52%)\n",
            "  adding: content/output/submit-dev-002376-2967.tsv (deflated 64%)\n",
            "  adding: content/output/eval_results_dev_000297-2967.txt (deflated 25%)\n",
            "  adding: content/output/test_logits_test_deberta_Base.txt (deflated 88%)\n",
            "  adding: content/output/eval_results_dev_000594-2967.txt (deflated 24%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}